---
title: "Darkness can not drive out darkness: Investigating Bias in Hate SpeechDetection Models"
collection: publications
type: "Workshop Long Paper"
date: 2022-05-27
authors: "Fatma Elsafoury"
venue: "ACL 2022"
venue-url: "https://sites.google.com/view/acl-srw-2022/home/"
proceedings: "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop"
#paperurl: '/files/publications/2022/SRW_2022/paper.pdf'
bibtexurl: '/files/publications/2022/SRW_2022/bib.bib'
abstract: "It has become crucial to develop tools for auto-
mated hate speech and abuse detection. These
tools would help to stop the bullies and the
haters and provide a safer environment for in-
dividuals especially from marginalized groups
to freely express themselves. However, recent
research shows that machine learning models
are biased and they might make the right deci-
sions for the wrong reasons. In this thesis, I
set out to understand the performance of hate
speech and abuse detection models and the dif-
ferent biases that could influence them. I show
that hate speech and abuse detection models
are not only subject to social bias but also to
other types of bias that have not been explored
before. Finally, I investigate the causal effect
of the social and intersectional bias on the per-
formance and unfairness of hate speech detec-
tion models."
---
<a href="/files/publications/2022/SRW_2022/paper.pdf"><img src="/images/paper_symbol.png" alt="Link to paper" style="width:22px;height:22px;"></a>
<a href="/files/publications/2022/SRW_2022/ACL_SRW_2022_Poster.pdf"><img src="/images/poster_symbol.png" alt="Link to poster" style="width:22px;height:22px;"></a>
