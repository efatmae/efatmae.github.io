---
title: "Thesis Distillation: Investigating The Impact of Bias in NLP Models on Hate Speech Detection"
collection: publications
type: "Pre-print"
date: 2023-08-31
authors: "Fatma Elsafoury"
venue: "Pre-print: arxiv"
#venue-url: "https://sites.google.com/view/acl-srw-2022/home/"
#proceedings: "Proceedings of the 60th Annual Meeting of the Association for Computational #Linguistics: Student Research Workshop"
#paperurl: '/files/publications/2022/SRW_2022/paper.pdf'
#bibtexurl: '/files/publications/2022/SRW_2022/bib.bib'
---
<a href="https://arxiv.org/abs/2308.16549"><img src="/images/paper_symbol.png" alt="Link to paper" style="width:42px;height:42px;"></a>



**Abstract:** This paper is a summary of the work in my PhD thesis. In which, I investigate the impact of bias in NLP models on the task of hate speech detection from three perspectives: explainability, offensive stereotyping bias, and fairness. I discuss the main takeaways from my thesis and how they can benefit the broader NLP community. Finally, I discuss important future research directions. The findings of my thesis suggest that bias in NLP models impacts the task of hate speech detection from all three perspectives. And that unless we start incorporating social sciences in studying bias in NLP models, we will not effectively overcome the current limitations of measuring and mitigating bias in NLP models.